# -*- coding: utf-8 -*-
#PI_DeepONet_POISSON.ipynb

#Automatically generated by Colaboratory.

#Original file is located at
    #https://colab.research.google.com/drive/1pbdcblMxIEIq8jyETygTseBUjVjdukq4


#"Backend supported: tensorflow.compat.v1, tensorflow, pytorch"



import numpy as np
import deepxde as dde
import matplotlib.pyplot as plt


# Poisson equation: u_xx = -f
def equation(x, y, f):
    dy_xx = dde.grad.hessian(y, x)
    return -dy_xx - f


# Domain is interval [0, 1]
geom = dde.geometry.Interval(0, 1)


# Zero Dirichlet BC
def u_boundary(_):
    return 0


def boundary(_, on_boundary):
    return on_boundary


bc = dde.icbc.DirichletBC(geom, u_boundary, boundary)

# Define PDE
pde = dde.data.PDE(
    geom,
    equation,
    bc,
    num_domain=100,
    num_boundary=2
)

# Function space for f(x) are RBF
space = dde.data.GRF(T=1, kernel="RBF", length_scale=0.2, N=512, interp="quadratic")

# Choose evaluation points
num_eval_points = 10
evaluation_points = geom.uniform_points(num_eval_points, boundary=True)

# Define PDE operator
pde_op = dde.data.PDEOperatorCartesianProd(
    pde,
    space,
    evaluation_points,
    num_function=100,
)

# Setup DeepONet
dim_x = 1
p = 32

"""# Treino com a função de ativação Tanh"""

net_tanh = dde.nn.DeepONetCartesianProd(
    [num_eval_points, 32, p],
    [dim_x, 32, p],
    activation="tanh",
    kernel_initializer="Glorot normal",
)

# Define and train model
model_tanh = dde.Model(pde_op, net_tanh)

if dde.backend.backend_name == "pytorch":
    dde.optimizers.set_LBFGS_options(maxiter=1000)
    model_tanh.compile("L-BFGS")
    model_tanh.train()
else:
    model_tanh.compile("adam", lr=0.001)
    losshistory_tanh, train_state_tanh=model_tanh.train(iterations=10000)

"""# Treino com a função de ativação ReLu"""

net_relu = dde.nn.DeepONetCartesianProd(
    [num_eval_points, 32, p],
    [dim_x, 32, p],
    activation="relu",
    kernel_initializer="Glorot normal",
)

# Define and train model
model_relu = dde.Model(pde_op, net_relu)

if dde.backend.backend_name == "pytorch":
    dde.optimizers.set_LBFGS_options(maxiter=1000)
    model_relu.compile("L-BFGS")
    model_relu.train()
else:
    model_relu.compile("adam", lr=0.001)
    losshistory_relu, train_state_relu=model_relu.train(iterations=10000)

"""# Treino com a função de ativação Sigmoid"""

net_sigmoid = dde.nn.DeepONetCartesianProd(
    [num_eval_points, 32, p],
    [dim_x, 32, p],
    activation="sigmoid",
    kernel_initializer="Glorot normal",
)

# Define and train model
model_sigmoid = dde.Model(pde_op, net_sigmoid)

if dde.backend.backend_name == "pytorch":
    dde.optimizers.set_LBFGS_options(maxiter=1000)
    model_sigmoid.compile("L-BFGS")
    model_sigmoid.train()
else:
    model_sigmoid.compile("adam", lr=0.001)
    losshistory_sigmoid, train_state_sigmoid=model_sigmoid.train(iterations=10000)

"""# Plote loss"""

def plot_loss_history(losshistory_tanh, losshistory_relu, losshistory_sigmoid, fname=None):
    """Plot the training and testing loss history.

    Note:
        You need to call ``plt.show()`` to show the figure.

    Args:
        loss_history: ``LossHistory`` instance. The first variable returned from
            ``Model.train()``.
        fname (string): If `fname` is a string (e.g., 'loss_history.png'), then save the
            figure to the file of the file name `fname`.
    """
    loss_train_tanh = np.sum(losshistory_tanh.loss_train, axis=1)
    loss_train_relu = np.sum(losshistory_relu.loss_train, axis=1)
    loss_train_sigmoid = np.sum(losshistory_sigmoid.loss_train, axis=1)

    #loss_test = np.sum(loss_history.loss_test, axis=1)

    plt.figure()
    plt.semilogy(losshistory_tanh.steps, loss_train_tanh, label="Função Tanh ")
    plt.semilogy(losshistory_relu.steps, loss_train_relu, label="Função ReLU")
    plt.semilogy(losshistory_sigmoid.steps, loss_train_sigmoid, label="Função Sigmoide")
    #plt.semilogy(loss_history.steps, loss_test, label="Test loss")
    '''
    for i in range(len(losshistory_tanh.metrics_test[0])):
        plt.semilogy(
            losshistory_tanh.steps,
            np.array(losshistory_tanh.metrics_test)[:, i],
            label="Test metric",
        )
    '''
    plt.xlabel("Iterações")
    plt.title("Perda de treinamento")
    plt.legend()

    if isinstance(fname, str):
        plt.savefig(fname)

plot_loss_history(losshistory_tanh, losshistory_relu, losshistory_sigmoid)

"""# Funções de teste 1"""

# Plot realisations 3 of f(x), essas funções f são ~ x^3  (basta olhar a plotagem),
#lembrando que a edp é: # Poisson equation: -u_xx = f
n = 10000
features = space.random(n)
fx = space.eval_batch(features, evaluation_points)
x = geom.uniform_points(100, boundary=True)

"""## TESTES Tanh

### Predição
"""

y1 = model_tanh.predict((fx, x)) # Assumimos que essa é a solução exata (pois ela prediz corretamente)

"""### Plot"""

#Poisson equation: Source term f(x) and solution \u03C6(x)
# Setup figure
#Predição da equação de Poisson em termos de f(x) e a solução \u03C6(x)

fig = plt.figure(figsize=(7, 8))
plt.subplot(3, 1, 1)
plt.title("Predição da equação de Poisson em termos de f(x) e a solução \u03C6(x)")
plt.ylabel("f(x)")
z = np.zeros_like(x)
plt.plot(x, z, 'k-', alpha=0.1)

# Plot source term f(x)
for i in range(n):
    plt.plot(evaluation_points, fx[i], '--')

# Plot solution predict \phi(x)
plt.subplot(3, 1, 2)
#plt.title("Predição \u03C6(x)")
plt.ylabel("Predição \u03C6(x)")
plt.plot(x, z, 'k-', alpha=0.1)
for i in range(n):
    plt.plot(x, y1[i], '-')
plt.xlabel("x")

# Plot solution exact \phi(x)
plt.subplot(3, 1, 3)
#plt.title("Exato \u03C6(x)")
plt.ylabel("Exato \u03C6(x)")
plt.plot(x, z, 'k-', alpha=0.1)
for i in range(n):
    plt.plot(x, y1[i], '.')
plt.xlabel("x")


plt.show()

# Métrica

print('Average test error for an unseen function: ', np.mean((y1 - y1)**2))
print('Average fractional test error for an unseen function: ', np.mean((y1 - y1)**2) / np.mean((y1)**2))



## TESTES ReLu

### Predição


y2 = model_relu.predict((fx, x))

### Plot

# Setup figure
fig = plt.figure(figsize=(7, 8))
plt.subplot(3, 1, 1)
plt.title("Predição da equação de Poisson em termos de f(x) e a solução \u03C6(x)")
plt.ylabel("f(x)")
z = np.zeros_like(x)
plt.plot(x, z, 'k-', alpha=0.1)

# Plot source term f(x)
for i in range(n):
    plt.plot(evaluation_points, fx[i], '--')

# Plot solution predict \phi(x)
plt.subplot(3, 1, 2)
#plt.title("Predição \u03C6(x)")
plt.ylabel("Predição \u03C6(x)")
plt.plot(x, z, 'k-', alpha=0.1)
for i in range(n):
    plt.plot(x, y2[i], '-')
plt.xlabel("x")


# Plot solution exact \phi(x)
plt.subplot(3, 1, 3)
#plt.title("Exato \u03C6(x)")
plt.ylabel("Exato \u03C6(x)")
plt.plot(x, z, 'k-', alpha=0.1)
for i in range(n):
    plt.plot(x, y1[i], '.')
plt.xlabel("x")


plt.show()

# Métrica


print('Average test error for an unseen function: ', np.mean((y1 - y2)**2))
print('Average fractional test error for an unseen function: ', np.mean((y1 - y2)**2) / np.mean((y1)**2))

"""## TESTES Sigmoid

### Predição
"""

y3 = model_sigmoid.predict((fx, x))

"""### Plot"""

# Setup figure
fig = plt.figure(figsize=(7, 8))
plt.subplot(3, 1, 1)
plt.title("Predição da equação de Poisson em termos de f(x) e a solução \u03C6(x)")
plt.ylabel("f(x)")
z = np.zeros_like(x)
plt.plot(x, z, 'k-', alpha=0.1)

# Plot source term f(x)
for i in range(n):
    plt.plot(evaluation_points, fx[i], '--')

# Plot solution predict \phi(x)
plt.subplot(3, 1, 2)
#plt.title("Predição \u03C6(x)")
plt.ylabel("Predição \u03C6(x)")
plt.plot(x, z, 'k-', alpha=0.1)
for i in range(n):
    plt.plot(x, y3[i], '-')
plt.xlabel("x")


# Plot solution exact \phi(x)
plt.subplot(3, 1, 3)
#plt.title("Exato \u03C6(x)")
plt.ylabel("Exato \u03C6(x)")
plt.plot(x, z, 'k-', alpha=0.1)
for i in range(n):
    plt.plot(x, y1[i], '.')
plt.xlabel("x")


plt.show()

# Métrica

print('Average test error for an unseen function: ', np.mean((y1 - y3)**2))
print('Average fractional test error for an unseen function: ', np.mean((y1 - y3)**2) / np.mean((y1)**2))

"""# Treinamento 2"""

# Domain is interval [-5, 5]
geom2 = dde.geometry.Interval(-5, 5) #dde.geometry.Interval(-5, 5)

bc2 = dde.icbc.DirichletBC(geom2, u_boundary, boundary)

# Define PDE
pde = dde.data.PDE(
    geom2,
    equation,
    bc2,
    num_domain=100,
    num_boundary=2
)

# Function space for f(x) are polynomials
degree = 3
space2 = dde.data.PowerSeries(N=degree+1)

# Choose evaluation points
num_eval_points2 = 10
evaluation_points2 = geom2.uniform_points(num_eval_points2, boundary=True)

# Define PDE operator
pde_op2 = dde.data.PDEOperatorCartesianProd(
    pde,
    space2,
    evaluation_points2,
    num_function=100,
)

# Setup DeepONet
dim_x = 1
p = 32






"""# Treino com a função de ativação Tanh"""

net_tanh2 = dde.nn.DeepONetCartesianProd(
    [num_eval_points2, 32, p],
    [dim_x, 32, p],
    activation="tanh",
    kernel_initializer="Glorot normal",
)

# Define and train model
model_tanh2 = dde.Model(pde_op2, net_tanh2)

if dde.backend.backend_name == "pytorch":
    dde.optimizers.set_LBFGS_options(maxiter=1000)
    model_tanh2.compile("L-BFGS")
    model_tanh2.train()
else:
    model_tanh2.compile("adam", lr=0.001)
    losshistory_tanh2, train_state_tanh2=model_tanh2.train(iterations=10000)

"""# Treino com a função de ativação ReLu"""

net_relu2 = dde.nn.DeepONetCartesianProd(
    [num_eval_points2, 32, p],
    [dim_x, 32, p],
    activation="relu",
    kernel_initializer="Glorot normal",
)

# Define and train model
model_relu2 = dde.Model(pde_op2, net_relu2)

if dde.backend.backend_name == "pytorch":
    dde.optimizers.set_LBFGS_options(maxiter=1000)
    model_relu2.compile("L-BFGS")
    model_relu2.train()
else:
    model_relu2.compile("adam", lr=0.001)
    losshistory_relu2, train_state_relu2=model_relu2.train(iterations=10000)

"""# Treino com a função de ativação Sigmoid"""

net_sigmoid2 = dde.nn.DeepONetCartesianProd(
    [num_eval_points2, 32, p],
    [dim_x, 32, p],
    activation="sigmoid",
    kernel_initializer="Glorot normal",
)

# Define and train model
model_sigmoid2 = dde.Model(pde_op2, net_sigmoid2)

if dde.backend.backend_name == "pytorch":
    dde.optimizers.set_LBFGS_options(maxiter=1000)
    model_sigmoid2.compile("L-BFGS")
    model_sigmoid2.train()
else:
    model_sigmoid2.compile("adam", lr=0.001)
    losshistory_sigmoid2, train_state_sigmoid2=model_sigmoid2.train(iterations=10000)

"""# Plote loss"""

def plot_loss_history(losshistory_tanh, losshistory_relu, losshistory_sigmoid, fname=None):
    """Plot the training and testing loss history.

    Note:
        You need to call ``plt.show()`` to show the figure.

    Args:
        loss_history: ``LossHistory`` instance. The first variable returned from
            ``Model.train()``.
        fname (string): If `fname` is a string (e.g., 'loss_history.png'), then save the
            figure to the file of the file name `fname`.
    """
    loss_train_tanh = np.sum(losshistory_tanh.loss_train, axis=1)
    loss_train_relu = np.sum(losshistory_relu.loss_train, axis=1)
    loss_train_sigmoid = np.sum(losshistory_sigmoid.loss_train, axis=1)

    #loss_test = np.sum(loss_history.loss_test, axis=1)

    plt.figure()
    plt.semilogy(losshistory_tanh.steps, loss_train_tanh, label="Função Tanh ")
    plt.semilogy(losshistory_relu.steps, loss_train_relu, label="Função ReLU")
    plt.semilogy(losshistory_sigmoid.steps, loss_train_sigmoid, label="Função Sigmoide")
    #plt.semilogy(loss_history.steps, loss_test, label="Test loss")
    '''
    for i in range(len(losshistory_tanh.metrics_test[0])):
        plt.semilogy(
            losshistory_tanh.steps,
            np.array(losshistory_tanh.metrics_test)[:, i],
            label="Test metric",
        )
    '''
    plt.xlabel("Iterações")
    plt.title("Perda de treinamento")
    plt.legend()

    if isinstance(fname, str):
        plt.savefig(fname)

plot_loss_history(losshistory_tanh2, losshistory_relu2, losshistory_sigmoid2)



"""# Funções de teste 2"""

# Plot realisations 3 of f(x), essas funções f são aleatorios  (basta olhar a plotagem),
#lembrando que a edp é: # Poisson equation: -u_xx = f
n = 10000
features2 = space2.random(n)
f2 = space2.eval_batch(features2, evaluation_points2)
x2 = geom2.uniform_points(100, boundary=True)

"""## TESTES 2 Tanh

### Predição
"""

y11 = model_tanh2.predict((f2, x2)) # Assumimos que essa é a solução exata (pois ela prediz corretamente)

"""### Plot"""

#Poisson equation: Source term f(x) and solution \u03C6(x)
# Setup figure
#Predição da equação de Poisson em termos de f(x) e a solução \u03C6(x)

fig = plt.figure(figsize=(7, 8))
plt.subplot(3, 1, 1)
plt.title("Predição da equação de Poisson em termos de f(x) e a solução \u03C6(x)")
plt.ylabel("f(x)")
z = np.zeros_like(x2)
plt.plot(x2, z, 'k-', alpha=0.1)

# Plot source term f(x)
for i in range(n):
    plt.plot(evaluation_points2, f2[i], '--')

# Plot solution predict \phi(x)
plt.subplot(3, 1, 2)
#plt.title("Predição \u03C6(x)")
plt.ylabel("Predição \u03C6(x)")
plt.plot(x2, z, 'k-', alpha=0.1)
for i in range(n):
    plt.plot(x2, y11[i], '-')
plt.xlabel("x")

# Plot solution exact \phi(x)
plt.subplot(3, 1, 3)
#plt.title("Exato \u03C6(x)")
plt.ylabel("Exato \u03C6(x)")
plt.plot(x2, z, 'k-', alpha=0.1)
for i in range(n):
    plt.plot(x2, y11[i], '.')
plt.xlabel("x")


plt.show()

# Métrica

print('Average test error for an unseen function: ', np.mean((y11 - y11)**2))
print('Average fractional test error for an unseen function: ', np.mean((y11 - y11)**2) / np.mean((y11)**2))

"""## TESTES 2 ReLU

### Predição
"""

y22 = model_relu2.predict((f2, x2))

"""### Plot"""

#Poisson equation: Source term f(x) and solution \u03C6(x)
# Setup figure
#Predição da equação de Poisson em termos de f(x) e a solução \u03C6(x)

fig = plt.figure(figsize=(7, 8))
plt.subplot(3, 1, 1)
plt.title("Predição da equação de Poisson em termos de f(x) e a solução \u03C6(x)")
plt.ylabel("f(x)")
z = np.zeros_like(x2)
plt.plot(x2, z, 'k-', alpha=0.1)

# Plot source term f(x)
for i in range(n):
    plt.plot(evaluation_points2, f2[i], '--')

# Plot solution predict \phi(x)
plt.subplot(3, 1, 2)
#plt.title("Predição \u03C6(x)")
plt.ylabel("Predição \u03C6(x)")
plt.plot(x2, z, 'k-', alpha=0.1)
for i in range(n):
    plt.plot(x2, y22[i], '-')
plt.xlabel("x")

# Plot solution exact \phi(x)
plt.subplot(3, 1, 3)
#plt.title("Exato \u03C6(x)")
plt.ylabel("Exato \u03C6(x)")
plt.plot(x2, z, 'k-', alpha=0.1)
for i in range(n):
    plt.plot(x2, y11[i], '.')
plt.xlabel("x")


plt.show()

# Métrica


print('Average test error for an unseen function: ', np.mean((y11 - y22)**2))
print('Average fractional test error for an unseen function: ', np.mean((y11 - y22)**2) / np.mean((y11)**2))

"""## TESTES 2 Sigmoid

### Predição
"""

y33 = model_sigmoid2.predict((f2, x2))

"""### Plot"""

#Poisson equation: Source term f(x) and solution \u03C6(x)
# Setup figure
#Predição da equação de Poisson em termos de f(x) e a solução \u03C6(x)

fig = plt.figure(figsize=(7, 8))
plt.subplot(3, 1, 1)
plt.title("Predição da equação de Poisson em termos de f(x) e a solução \u03C6(x)")
plt.ylabel("f(x)")
z = np.zeros_like(x2)
plt.plot(x2, z, 'k-', alpha=0.1)

# Plot source term f(x)
for i in range(n):
    plt.plot(evaluation_points2, f2[i], '--')

# Plot solution predict \phi(x)
plt.subplot(3, 1, 2)
#plt.title("Predição \u03C6(x)")
plt.ylabel("Predição \u03C6(x)")
plt.plot(x2, z, 'k-', alpha=0.1)
for i in range(n):
    plt.plot(x2, y33[i], '-')
plt.xlabel("x")

# Plot solution exact \phi(x)
plt.subplot(3, 1, 3)
#plt.title("Exato \u03C6(x)")
plt.ylabel("Exato \u03C6(x)")
plt.plot(x2, z, 'k-', alpha=0.1)
for i in range(n):
    plt.plot(x2, y33[i], '.')
plt.xlabel("x")


plt.show()

# Métrica


print('Average test error for an unseen function: ', np.mean((y11 - y33)**2))
print('Average fractional test error for an unseen function: ', np.mean((y11 - y33)**2) / np.mean((y11)**2))

